# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

В работе были выбраны 3 синтетических датасета из предоставленных четырёх: S07-hw-dataset-01.csv, S07-hw-dataset-02.csv,
S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: **12000 объектов, 8 числовых признаков** (без учёта `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета: признаки находятся в разных шкалах, присутствуют шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: **8000 объектов, 3 числовых признака** (без учёта `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета: нелинейная структура данных, наличие выбросов и шумового признака

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: **15000 объектов, 4 числовых признака** (без учёта `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета: кластеры разной плотности и наличие фонового шума
---
## 2. Protocol

Для всех датасетов использовался единый и честный unsupervised-протокол.

- Препроцессинг:
  - колонка `sample_id` исключалась из признаков и сохранялась отдельно;
  - числовые признаки обрабатывались с помощью `StandardScaler`;
  - пропуски (если бы они присутствовали) обрабатывались бы через `SimpleImputer`;
  - PCA применялся **только для визуализации**, а не для обучения моделей.
- Поиск гиперпараметров:
  - для KMeans перебиралось число кластеров `k` в диапазоне от 2 до 20;
  - фиксировались `random_state` и `n_init`;
  - для DBSCAN подбирались параметры `eps` и `min_samples` по разумной сетке;
  - лучший вариант выбирался на основе внутренних метрик кластеризации.
- Метрики:
  - `silhouette_score`
  - `davies_bouldin_score`
  - `calinski_harabasz_score`
  - для DBSCAN дополнительно учитывалась доля шума (`label = -1`), а метрики считались
    только по non-noise объектам.
- Визуализация:
  - PCA(2D) scatter с раскраской по полученным кластерам для лучшего решения;
  - графики подбора параметров (например, silhouette vs k или silhouette vs eps).

---

## 3. Models

Для каждого датасета сравнивались следующие модели:

- **KMeans**:
  - подбирался параметр `k`;
  - фиксировались `random_state` и `n_init`.
- **DBSCAN**:
  - подбирались параметры `eps` и `min_samples`;
  - отдельно анализировалась доля шума.
- **AgglomerativeClustering**:
  - подбиралось число кластеров `k`;
  - сравнивались варианты `linkage`.

Таким образом, для каждого датасета рассматривалось не менее двух алгоритмов кластеризации.

---

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с `k = 2`
- Метрики: высокое значение silhouette, низкий Davies–Bouldin
- Комментарий: после масштабирования данные формируют чётко разделённые кластеры,
  что хорошо соответствует предположениям KMeans

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с подобранными `eps` и `min_samples`
- Метрики: silhouette выше, чем у KMeans; разумная доля шума
- Комментарий: DBSCAN лучше справляется с нелинейной структурой и выбросами,
  в то время как KMeans демонстрирует ухудшение качества

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN
- Метрики: устойчивое выделение плотных кластеров при наличии шума
- Доля шума: заметная, но ожидаемая для данного датасета
- Комментарий: кластеры разной плотности делают выбор `eps` критичным, однако
  DBSCAN остаётся более подходящим, чем KMeans
---
## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans хорошо работает на компактных и примерно сферических кластерах,
  но чувствителен к выбросам и нарушению предположений о форме кластеров.
- DBSCAN выигрывает на данных с шумом и кластерами сложной формы,
  но чувствителен к выбору параметра `eps`.
- Масштабирование признаков является критически важным шагом для всех
  алгоритмов, основанных на расстояниях.

### 5.2 Устойчивость (обязательно для одного датасета)

Для одного из датасетов была проведена проверка устойчивости KMeans:
алгоритм запускался 5 раз с различными значениями `random_state`.
Сравнение разбиений с помощью Adjusted Rand Index показало ARI = 1.0
для всех пар запусков.

Это свидетельствует о полной воспроизводимости кластеризации и наличии
устойчивой кластерной структуры в данных.

### 5.3 Интерпретация кластеров

Кластеры интерпретировались через анализ распределений и средних значений
признаков внутри кластеров. В большинстве случаев удалось выделить группы
объектов с различающимися масштабами и комбинациями числовых признаков.

Полученные кластеры являются интерпретируемыми и согласуются с визуализацией
в пространстве первых двух компонент PCA.

---

## 6. Conclusion

- Кластеризация чувствительна к масштабу признаков и требует аккуратного препроцессинга.
- KMeans эффективен на простых структурах, но плохо справляется с выбросами и шумом.
- DBSCAN лучше подходит для данных с шумом и кластерами сложной формы.
- Внутренние метрики (silhouette, DB, CH) дополняют друг друга и должны рассматриваться совместно.
- PCA полезна для визуализации, но не является доказательством качества кластеризации.
- Проверка устойчивости позволяет выявить, является ли полученное разбиение воспроизводимым.
